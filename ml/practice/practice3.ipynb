{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cdd0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e580e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f3873df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    median_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    explained_variance_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58cd618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_search(X_train, y_train):\n",
    "    print(\"\\n[STEP] Performing RandomizedSearchCV...\")\n",
    "\n",
    "    base_rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    rf = MultiOutputRegressor(base_rf)\n",
    "\n",
    "    param_dist = {\n",
    "        \"estimator__n_estimators\": randint(20, 35),\n",
    "        \"estimator__max_depth\": [10, 15, 20],\n",
    "        \"estimator__min_samples_split\": randint(2, 6),\n",
    "        \"estimator__min_samples_leaf\": randint(1, 4),\n",
    "        \"estimator__max_features\": [0.4, 0.5, 0.6],\n",
    "        \"estimator__max_leaf_nodes\": [100, 200, None]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=5,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=2,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(f\"[INFO] Best Parameters: {random_search.best_params_}\")\n",
    "    return random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d62c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, X_test, y_test, model_path, start_time):\n",
    "    print(\"\\n[STEP] Evaluating model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    medae = median_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Absolute Error (MAE)         : {mae:.4f}\")\n",
    "    print(f\"Mean Squared Error (MSE)          : {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE)    : {rmse:.4f}\")\n",
    "    print(f\"R² Score                          : {r2:.4f}\")\n",
    "    print(f\"Median Absolute Error (MedAE)     : {medae:.4f}\")\n",
    "    print(f\"Mean Absolute Percentage Error    : {mape:.4f}\")\n",
    "    print(f\"Explained Variance Score (EVS)    : {evs:.4f}\")\n",
    "\n",
    "\n",
    "    print(\"\\n[STEP] Saving model to disk...\")\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    joblib.dump(model, model_path, compress=3)\n",
    "\n",
    "    # Estimate model size\n",
    "    size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "    print(f\"[INFO] Model saved to: {model_path} ({size_mb:.2f} MB)\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"[INFO] Total training + saving time: {round(total_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84d1dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_temperature_data(csv_path):\n",
    "    print(f\"\\n[INFO] Reading CSV: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"Original DataFrame shape:\", df.shape)\n",
    "    \n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(\"[DEBUG] Warning: Null values found. Proceeding anyway.\")\n",
    "\n",
    "    # Rename and convert datetime\n",
    "    df.rename(columns={'temperature_2m (°C)': 'temperature', 'time': 'datetime'}, inplace=True)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime').reset_index(drop=True)\n",
    "    print(\"[INFO] Converted datetime and sorted. Shape:\", df.shape)\n",
    "\n",
    "    # Lag features\n",
    "    for i in range(1, 25):\n",
    "        df[f'temp_t-{i}'] = df['temperature'].shift(i)\n",
    "\n",
    "    for i in range(0, 24):\n",
    "        df[f'target_t+{i+1}'] = df['temperature'].shift(-(i+1))\n",
    "\n",
    "    print(\"[DEBUG] After adding lag + target. Shape:\", df.shape)\n",
    "    print(\"[DEBUG] Preview of columns:\", df.columns.tolist())\n",
    "\n",
    "    # Drop NA from lag creation\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    print(\"[INFO] Dropped NaNs. Final usable shape:\", df.shape)\n",
    "\n",
    "    # Define X and y\n",
    "    feature_cols = [f'temp_t-{i}' for i in range(1, 25)]  # all 24 lags\n",
    "    target_cols = [f'target_t+{i+1}' for i in range(24)] \n",
    "\n",
    "    x = df[feature_cols]\n",
    "    y = df[target_cols]\n",
    "\n",
    "    print(\"[DEBUG] Features shape:\", x.shape)\n",
    "    print(\"[DEBUG] Target shape:\", y.shape)\n",
    "    print(\"[DEBUG] Sample features:\\n\", x.head(2))\n",
    "    print(\"[DEBUG] Sample target:\\n\", y.head(2))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6248609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Model Training\n",
    "def train_and_save_model(csv_path, model_path=\"ml/models/temp_next48hr_model.joblib\"):\n",
    "    start_time = time.time()\n",
    "    print(\"\\n[STEP] Loading and preprocessing data...\")\n",
    "    x, y = preprocess_temperature_data(csv_path)\n",
    "\n",
    "    print(\"\\n[STEP] Splitting dataset into train/test...\")\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    print(f\"[INFO] x_train: {x_train.shape}, x_test: {x_test.shape}\")\n",
    "\n",
    "    print(\"\\n[STEP] Training RandomForest model using RandomizedSearchCV...\")\n",
    "    model = perform_random_search(x_train, y_train)\n",
    "\n",
    "    \n",
    "    evaluation(model, x_test, y_test, model_path, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43f5e283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP] Loading and preprocessing data...\n",
      "\n",
      "[INFO] Reading CSV: /home/aditya/flask/ml/dataset/open-meteo-18.62N74.00E561m.csv\n",
      "Original DataFrame shape: (131184, 10)\n",
      "[INFO] Converted datetime and sorted. Shape: (131184, 10)\n",
      "[DEBUG] After adding lag + target. Shape: (131184, 58)\n",
      "[DEBUG] Preview of columns: ['location_id', 'datetime', 'temperature', 'relative_humidity_2m (%)', 'dew_point_2m (°C)', 'rain (mm)', 'pressure_msl (hPa)', 'surface_pressure (hPa)', 'cloud_cover (%)', 'wind_speed_10m (km/h)', 'temp_t-1', 'temp_t-2', 'temp_t-3', 'temp_t-4', 'temp_t-5', 'temp_t-6', 'temp_t-7', 'temp_t-8', 'temp_t-9', 'temp_t-10', 'temp_t-11', 'temp_t-12', 'temp_t-13', 'temp_t-14', 'temp_t-15', 'temp_t-16', 'temp_t-17', 'temp_t-18', 'temp_t-19', 'temp_t-20', 'temp_t-21', 'temp_t-22', 'temp_t-23', 'temp_t-24', 'target_t+1', 'target_t+2', 'target_t+3', 'target_t+4', 'target_t+5', 'target_t+6', 'target_t+7', 'target_t+8', 'target_t+9', 'target_t+10', 'target_t+11', 'target_t+12', 'target_t+13', 'target_t+14', 'target_t+15', 'target_t+16', 'target_t+17', 'target_t+18', 'target_t+19', 'target_t+20', 'target_t+21', 'target_t+22', 'target_t+23', 'target_t+24']\n",
      "[INFO] Dropped NaNs. Final usable shape: (131136, 58)\n",
      "[DEBUG] Features shape: (131136, 24)\n",
      "[DEBUG] Target shape: (131136, 24)\n",
      "[DEBUG] Sample features:\n",
      "    temp_t-1  temp_t-2  temp_t-3  temp_t-4  temp_t-5  temp_t-6  temp_t-7  \\\n",
      "0      19.8      17.4      15.9      20.8      16.0      16.8      13.2   \n",
      "1      24.6      19.8      17.4      15.9      20.8      16.0      16.8   \n",
      "\n",
      "   temp_t-8  temp_t-9  temp_t-10  ...  temp_t-15  temp_t-16  temp_t-17  \\\n",
      "0      14.2      12.2       18.0  ...       18.1       13.1       17.0   \n",
      "1      13.2      14.2       12.2  ...       14.1       18.1       13.1   \n",
      "\n",
      "   temp_t-18  temp_t-19  temp_t-20  temp_t-21  temp_t-22  temp_t-23  temp_t-24  \n",
      "0       13.4       12.4       14.5       18.5       13.6       17.4       13.7  \n",
      "1       17.0       13.4       12.4       14.5       18.5       13.6       17.4  \n",
      "\n",
      "[2 rows x 24 columns]\n",
      "[DEBUG] Sample target:\n",
      "    target_t+1  target_t+2  target_t+3  target_t+4  target_t+5  target_t+6  \\\n",
      "0        19.7        22.4        23.6        22.0        21.6        23.4   \n",
      "1        22.4        23.6        22.0        21.6        23.4        26.4   \n",
      "\n",
      "   target_t+7  target_t+8  target_t+9  target_t+10  ...  target_t+15  \\\n",
      "0        26.4        24.6        25.5         27.8  ...         26.2   \n",
      "1        24.6        25.5        27.8         26.3  ...         27.2   \n",
      "\n",
      "   target_t+16  target_t+17  target_t+18  target_t+19  target_t+20  \\\n",
      "0         27.2         28.4         30.6         29.2         29.6   \n",
      "1         28.4         30.6         29.2         29.6         30.4   \n",
      "\n",
      "   target_t+21  target_t+22  target_t+23  target_t+24  \n",
      "0         30.4         28.4         29.8         30.7  \n",
      "1         28.4         29.8         30.7         30.9  \n",
      "\n",
      "[2 rows x 24 columns]\n",
      "\n",
      "[STEP] Splitting dataset into train/test...\n",
      "[INFO] x_train: (104908, 24), x_test: (26228, 24)\n",
      "\n",
      "[STEP] Training RandomForest model using RandomizedSearchCV...\n",
      "\n",
      "[STEP] Performing RandomizedSearchCV...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=15, estimator__max_features=0.5, estimator__max_leaf_nodes=100, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=30; total time= 3.2min\n",
      "[CV] END estimator__max_depth=15, estimator__max_features=0.5, estimator__max_leaf_nodes=100, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=30; total time= 3.2min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=0.4, estimator__max_leaf_nodes=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=21; total time= 3.6min\n",
      "[CV] END estimator__max_depth=15, estimator__max_features=0.5, estimator__max_leaf_nodes=200, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=31; total time= 3.6min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=0.4, estimator__max_leaf_nodes=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=21; total time= 3.6min\n",
      "[CV] END estimator__max_depth=15, estimator__max_features=0.5, estimator__max_leaf_nodes=200, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=31; total time= 3.6min\n",
      "[CV] END estimator__max_depth=10, estimator__max_features=0.6, estimator__max_leaf_nodes=200, estimator__min_samples_leaf=3, estimator__min_samples_split=4, estimator__n_estimators=30; total time= 3.7min\n",
      "[CV] END estimator__max_depth=10, estimator__max_features=0.6, estimator__max_leaf_nodes=200, estimator__min_samples_leaf=3, estimator__min_samples_split=4, estimator__n_estimators=30; total time= 3.7min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=0.4, estimator__max_leaf_nodes=None, estimator__min_samples_leaf=3, estimator__min_samples_split=5, estimator__n_estimators=32; total time= 3.8min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=0.4, estimator__max_leaf_nodes=None, estimator__min_samples_leaf=3, estimator__min_samples_split=5, estimator__n_estimators=32; total time= 3.8min\n",
      "[INFO] Best Parameters: {'estimator__max_depth': 20, 'estimator__max_features': 0.4, 'estimator__max_leaf_nodes': None, 'estimator__min_samples_leaf': 3, 'estimator__min_samples_split': 5, 'estimator__n_estimators': 32}\n",
      "\n",
      "[STEP] Evaluating model...\n",
      "Mean Absolute Error (MAE)         : 1.6815\n",
      "Mean Squared Error (MSE)          : 5.3168\n",
      "Root Mean Squared Error (RMSE)    : 2.2673\n",
      "R² Score                          : 0.8022\n",
      "Median Absolute Error (MedAE)     : 1.2634\n",
      "Mean Absolute Percentage Error    : 0.0704\n",
      "Explained Variance Score (EVS)    : 0.8022\n",
      "\n",
      "[STEP] Saving model to disk...\n",
      "[INFO] Model saved to: ml/models/temp_next48hr_model.joblib (360.32 MB)\n",
      "[INFO] Total training + saving time: 311.76 seconds\n"
     ]
    }
   ],
   "source": [
    "# ----------- Step 3: Run ------------\n",
    "# Replace with your actual file path\n",
    "train_and_save_model(\"/home/aditya/flask/ml/dataset/open-meteo-18.62N74.00E561m.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
